{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n",
      "initial policy:\n",
      "---------------------------\n",
      "  R  |  D  |  R  |     |\n",
      "---------------------------\n",
      "  R  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  U  |  U  |  D  |\n",
      "1 0.8745512956880981\n",
      "2 0.008745512956880988\n",
      "3 8.723750461495094e-05\n",
      "values:\n",
      "---------------------------\n",
      "-0.10|-0.09| 1.00| 0.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.09| 0.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n",
      "policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  U  |  L  |\n"
     ]
    }
   ],
   "source": [
    "# https://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-python\n",
    "# https://www.udemy.com/artificial-intelligence-reinforcement-learning-in-python\n",
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from grid_world import standard_grid, negative_grid\n",
    "from iterative_policy_evaluation import print_values, print_policy\n",
    "\n",
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = .01\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')\n",
    "result_array = np.array([])\n",
    "# this is deterministic\n",
    "# all p(s',r|s,a) = 1 or 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # this grid gives you a reward of -0.1 for every non-terminal state\n",
    "  # we want to see if this will encourage finding a shorter path to the goal\n",
    "  grid = negative_grid()\n",
    "\n",
    "  # print rewards\n",
    "  print(\"rewards:\")\n",
    "  print_values(grid.rewards, grid)\n",
    "\n",
    "  # state -> action\n",
    "  # we'll randomly choose an action and update as we learn\n",
    "  policy = {}\n",
    "  for s in grid.actions.keys():\n",
    "    policy[s] = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "\n",
    "  # initial policy\n",
    "  print(\"initial policy:\")\n",
    "  print_policy(policy, grid)\n",
    "\n",
    "  # initialize V(s)\n",
    "  V = {}\n",
    "  states = grid.all_states()\n",
    "  for s in states:\n",
    "    # V[s] = 0\n",
    "    if s in grid.actions:\n",
    "      V[s] = np.random.random()\n",
    "    else:\n",
    "      # terminal state\n",
    "      V[s] = 0\n",
    "\n",
    "  # repeat until convergence\n",
    "  # V[s] = max[a]{ sum[s',r] { p(s',r|s,a)[r + gamma*V[s']] } }\n",
    "  count = 0\n",
    "  while True:\n",
    "    count += 1\n",
    "    biggest_change = 0\n",
    "    for s in states:\n",
    "      old_v = V[s]\n",
    "\n",
    "      # V(s) only has value if it's not a terminal state\n",
    "      if s in policy:\n",
    "        new_v = float('-inf')\n",
    "        for a in ALL_POSSIBLE_ACTIONS:\n",
    "          grid.set_state(s)\n",
    "          r = grid.move(a)\n",
    "          v = r + GAMMA * V[grid.current_state()]\n",
    "          if v > new_v:\n",
    "            new_v = v\n",
    "        V[s] = new_v\n",
    "        biggest_change = max(biggest_change, np.abs(old_v - V[s]))\n",
    "        \n",
    "        result_array = np.append(result_array, biggest_change)\n",
    "    print(count,biggest_change)\n",
    "\n",
    "    if biggest_change < SMALL_ENOUGH:\n",
    "      break\n",
    "\n",
    "  # find a policy that leads to optimal value function\n",
    "  for s in policy.keys():\n",
    "    best_a = None\n",
    "    best_value = float('-inf')\n",
    "    # loop through all possible actions to find the best current action\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "      grid.set_state(s)\n",
    "      r = grid.move(a)\n",
    "      v = r + GAMMA * V[grid.current_state()]\n",
    "      if v > best_value:\n",
    "        best_value = v\n",
    "        best_a = a\n",
    "    policy[s] = best_a\n",
    "\n",
    "  # our goal here is to verify that we get the same answer as with policy iteration\n",
    "  print(\"values:\")\n",
    "  print_values(V, grid)\n",
    "  print(\"policy:\")\n",
    "  print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nASCD/h9WnR+eJZSgiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(result_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (1, 0),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3)}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
